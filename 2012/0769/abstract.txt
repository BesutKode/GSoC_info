Today, mobile platforms (such as NVIDIA Tegra 3) are equipped with multi-core CPUs and GPUs that have shown promising capabilities in creating real-time applications that involves image processing and 3D rendering.  The increasing capabilities of these devices have opened possibilities of creating interactive applications that were only available to workstation desktops in the past. 
The goal of this project is to port over and further optimize some of the key features from the PCL library to run on Android devices. Ultimately, we would create a platform that allows developers to create interactive applications using the Microsoft Kinect, Tegra 3, and PCL all out of the box with minimum efforts. Together, we hope this would encourage developers to explore applications that utilize these hardware and provide richer and unique user experiences. Additionally, computational intense tasks such as feature extraction/recognition can be offloaded to a remote server. Then, the computed results are transferred back to the mobile devices in real-time. By decoupling the computation from the devices, we could support a large variety of platforms despite the hardware limitation on some of the mobile devices.