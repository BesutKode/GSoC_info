The project idea is to extend Rapid with code that facilitates the submission, monitoring and execution of jobs through Hadoop Framework. Rapid is a technology to quickly create web portal interfaces to execute applications on large remote clusters. Apache Hadoop is a framework for running applications on large clusters, implementing Map/Reduce and a distributed file system (HDFS). The project goal is to add a module to Rapid, such that it can communicate with the Apache Hadoop Framework.